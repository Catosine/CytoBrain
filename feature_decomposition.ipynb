{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in range(1, 9):\n",
    "\n",
    "    subj = \"subj0{}\".format(i)\n",
    "    path = \"../../data.nosync/{}\".format(subj)+\"/{}_split/{}_features/vit-gpt2-image-captioning/decoder-raw\"\n",
    "    \n",
    "    print(\"==========================<{}>==========================\".format(subj))\n",
    "\n",
    "    for layer in [-1, -2, -3, -4]:\n",
    "\n",
    "        print(\"last layer: #{}\".format(-layer))\n",
    "\n",
    "        # get all data\n",
    "        feats = list()\n",
    "        files = os.listdir(path.format(\"training\", \"training\"))\n",
    "        for x in tqdm(files):\n",
    "            dat = np.load(os.path.join(path.format(\"training\", \"training\"), x))\n",
    "            feats.append(dat[layer].reshape(-1))\n",
    "\n",
    "        test_files = os.listdir(path.format(\"test\", \"test\"))\n",
    "        for x in tqdm(test_files):\n",
    "            dat = np.load(os.path.join(path.format(\"test\", \"test\"), x))\n",
    "            feats.append(dat[layer].reshape(-1))\n",
    "\n",
    "        files += test_files\n",
    "        feats = np.vstack(feats)\n",
    "        feats = StandardScaler().fit_transform(feats)\n",
    "\n",
    "        print(\"Start PCA Reduction\")\n",
    "        pca = PCA(n_components=512)\n",
    "        pca.fit(X=feats)\n",
    "\n",
    "        reduced_feats = pca.transform(feats)\n",
    "\n",
    "        train_save = \"../../data.nosync/{}/{}_split/{}_features/vit-gpt2-image-captioning/decoder-last{}-pca-512\".format(\n",
    "            subj, \"training\", \"training\", -layer)\n",
    "        \n",
    "        test_save = \"../../data.nosync/{}/{}_split/{}_features/vit-gpt2-image-captioning/decoder-last{}-pca-512\".format(\n",
    "            subj, \"test\", \"test\", -layer)\n",
    "\n",
    "        if not os.path.isdir(train_save):\n",
    "            os.makedirs(train_save)\n",
    "\n",
    "        if not os.path.isdir(test_save):\n",
    "            os.makedirs(test_save)\n",
    "\n",
    "        print(\"Saving...\")\n",
    "\n",
    "        for f, x in zip(reduced_feats, files):\n",
    "            \n",
    "            p = train_save if x.split(\"-\")[0] == \"train\" else test_save\n",
    "            np.save(os.path.join(p, x), f.astype(np.float32))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algonauts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
